{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # goes to project root\n",
    "\n",
    "from preparation.generators.Generator import Generator\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our Generator object requires one parameter\n",
    "# grab the attr_map and load it in as a dictionary\n",
    "with open('../data/functional/races.json', 'rb') as f:\n",
    "    attr_map = json.load(f)\n",
    "\n",
    "# instantiate a dataset Generator object\n",
    "hr = Generator(attr_map=attr_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 1000 replays out of 3456.\n"
     ]
    }
   ],
   "source": [
    "# loads replay references into memory\n",
    "dfs = hr.load_replays('../data/raw/**/*.SC2Replay', limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading replay 1000/1000 | Loaded 100.00% of total!\n",
      "\n",
      "END: Found {'P': 317, 'T': 285, 'Z': 0} valid games (total=602) out of 3456.\n"
     ]
    }
   ],
   "source": [
    "# We're storing all dataframes by key\n",
    "# Keys are P, T, and Z\n",
    "# These represent each race\n",
    "dfs = hr.getData(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Negative total by column for P:\n  None\n\nNegative total by column for T:\n  orbitalcommand -34.0\n\nNegative total by column for Z:\n  None\n\n"
     ]
    }
   ],
   "source": [
    "for k in dfs.keys():\n",
    "    tmp_df = dfs[k] # grab a dataset by its player 1's race\n",
    "\n",
    "    # go through all quantitative columns and check if their values are < 0\n",
    "    # meaning it will return true if they are negative\n",
    "    # then, since True == 1 and False == 0, get the result of summation per column\n",
    "    negative_check = tmp_df[tmp_df.select_dtypes(exclude=['object']) < 0].sum()\n",
    "    # only keep columns that are actually negative\n",
    "    negative_check = negative_check[negative_check < 0]\n",
    "\n",
    "    # this is not necessary\n",
    "    # I just like how nice it looks\n",
    "    col_negative_sum_zip = list(zip(negative_check.index.to_list(), negative_check.to_list()))\n",
    "    if len(col_negative_sum_zip) > 0:\n",
    "        col_negative_sum_zip = '\\n'.join(['{} {}'.format(*n) for n in col_negative_sum_zip])\n",
    "    else:\n",
    "        col_negative_sum_zip = None\n",
    "\n",
    "    print('Negative total by column for {}:\\n  {}\\n'.format(k, col_negative_sum_zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving as ../data/processed/protoss_317_jan-21-2021_224018.csv\n",
      "Saving as ../data/processed/terran_285_jan-21-2021_224018.csv\n",
      "Dataframe for zerg is empty, so skipping.\n"
     ]
    }
   ],
   "source": [
    "name_map = {\n",
    "    'T': 'terran',\n",
    "    'P': 'protoss',\n",
    "    'Z': 'zerg'\n",
    "}\n",
    "\n",
    "for k in dfs.keys():\n",
    "    # get the race name by key map\n",
    "    name = name_map[k]\n",
    "\n",
    "    # only generate dataset csv if it actually contains stuff\n",
    "    if len(dfs[k]) == 0:\n",
    "        print('Dataframe for {} is empty, so skipping.'.format(name))\n",
    "        continue\n",
    "\n",
    "    tmp_df = dfs[k] # grab a dataset by its player 1's race\n",
    "\n",
    "    # we're storing the number of matches stored in each dataframe\n",
    "    # so, get its respective total match count by its race\n",
    "    total_matches = hr.valid_matches[k]\n",
    "    # create a date string for the current time and date\n",
    "    date_str = datetime.datetime.now().strftime('%b-%d-%Y_%H%M%S').lower()\n",
    "    # create a descriptive csv file name with:\n",
    "    # - player 1's race\n",
    "    # - the number of matches it contains\n",
    "    # - when the dataset was generated\n",
    "    filename = '{}_{}_{}'.format(name, total_matches, date_str)\n",
    "    path = '../data/processed/{}.csv'.format(filename)\n",
    "\n",
    "    print('Saving as', path)\n",
    "    tmp_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}